{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "import lightgbm as lgb\n",
    "\n",
    "from testbed.models.quantile_regression import QuantileRegression\n",
    "from testbed.models.treeffuser import Treeffuser\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "\n",
    "from testbed.models.ngboost import NGBoostGaussian, NGBoostMixtureGaussian, NGBoostPoisson\n",
    "from testbed.models.base_model import BayesOptProbabilisticModel\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from jaxtyping import Float, Array\n",
    "from typing import List, Callable\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from testbed.metrics.log_likelihood import LogLikelihoodFromSamplesMetric\n",
    "from testbed.metrics.crps import CRPS\n",
    "\n",
    "\n",
    "path = \"../src/testbed/data/m5\"\n",
    "\n",
    "# load autoreload extension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are config variables\n",
    "\n",
    "PROCESS_FROM_SCRATCH = True\n",
    "USE_SUBSET = True\n",
    "CONTEXT_LENGTH = 20\n",
    "RUN_DEPRECATED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN DATA\n",
    "\n",
    "sell_prices_df = pd.read_csv(Path(path) / \"sell_prices.csv\")\n",
    "sales_train_validation_df = pd.read_csv(Path(path) / \"sales_train_validation.csv\")\n",
    "calendar_df = pd.read_csv(Path(path) / \"calendar.csv\")\n",
    "\n",
    "print(\"\\ncolumns of sell_prices_df:\")\n",
    "[print(col) for col in sell_prices_df.columns]\n",
    "print(\"\\ncolumns of sales_train_validation_df:\")\n",
    "[print(col) for col in sales_train_validation_df.columns if not col.startswith(\"d_\")]\n",
    "print(\"\\ncolumns of calendar_df:\") # ommit d_1, d_2, ..., d_1913\n",
    "[print(col) for col in calendar_df.columns if not col.startswith(\"d_\")]\n",
    "\n",
    "\"\"\n",
    "\n",
    "# print number of zeros\n",
    "print(\"number of zeros in sales_train_validation_df: \", (sales_train_validation_df == 0).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_zeros = sales_train_validation_df.isin([0]).sum().sum()\n",
    "#total_entries =   sales_train_validation_df.\n",
    "\n",
    "items_sold_cols = sales_train_validation_df.columns[sales_train_validation_df.columns.str.startswith(\"d_\")]\n",
    "num_zeros = (sales_train_validation_df[items_sold_cols] == 0).sum().sum()\n",
    "total_entries = sales_train_validation_df[items_sold_cols].shape[0] * sales_train_validation_df[items_sold_cols].shape[1]\n",
    "\n",
    "print(f\"number of zeros in sales_train_validation_df: {num_zeros} out of {total_entries} entries\")\n",
    "print(f\"percentage of zeros in sales_train_validation_df: {num_zeros / total_entries * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add explicit columns for the day, month, year for ease of processing\n",
    "calendar_df[\"date\"] = pd.to_datetime(calendar_df[\"date\"])\n",
    "calendar_df[\"day\"] = calendar_df[\"date\"].dt.day\n",
    "calendar_df[\"month\"] = calendar_df[\"date\"].dt.month\n",
    "calendar_df[\"year\"] = calendar_df[\"date\"].dt.year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief snapshots of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_prices_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_ITEMS = 5000\n",
    "# select a random subset of items\n",
    "if USE_SUBSET:\n",
    "    np.random.seed(0)\n",
    "    unique_ids = sales_train_validation_df[\"id\"].unique()\n",
    "    ids = np.random.choice(sales_train_validation_df[\"id\"].unique(), TOTAL_ITEMS, replace=False)\n",
    "    sales_train_validation_df_sub = sales_train_validation_df[sales_train_validation_df[\"id\"].isin(ids)]\n",
    "    item_ids = sales_train_validation_df_sub[\"item_id\"].unique()\n",
    "    sell_prices_df_sub = sell_prices_df[sell_prices_df[\"item_id\"].isin(item_ids)]\n",
    "    calendar_df_sub = calendar_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns_sales_train_validation.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy for processing the data is going to be the following. 1) We are going to have X and y where y is the next days sales for a given product. 3) X is made up of 10 previous prices, day of the week, + event types, cat_id, store_id, state_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_train_test(sales_train_validation_df: pd.DataFrame, calendar_df: pd.DataFrame, sell_prices_df: pd.DataFrame, context_length: int, test_percentage: float, percentage_omittied: int = 0): #type annotation too long\n",
    "    \"\"\"\n",
    "    This function processes the data and returns the training and test data in two ways:\n",
    "    - undifferentiated: a list of all training and test data (X_train, y_train, X_test, y_test)\n",
    "    - differentiated: a list of training and test data for each product (X_train_prod, y_train_prod, X_test_prod, y_test_prod)\n",
    "        where X_train_prod[i] contains a list of all X_train values for the product i with similar grouping for y_train_prod and test\n",
    "\n",
    "    This assumes from the dataframes that\n",
    "    - sales_train_validation_df:\n",
    "        - has columns with the format d_1, d_2, ...\n",
    "        - has columns item_id and store_id\n",
    "    - calendar_df:\n",
    "        - wday, month, event_name_1, event_name_2\n",
    "    - sell_prices_df:\n",
    "        - item_id, store_id, sell_price\n",
    "\n",
    "    - percentage_omittied: percentage of the data to be omitted from the training data and the test data\n",
    "        (randomly selected)\n",
    "\n",
    "    Returns:\n",
    "    - undifferentiated: Tuple of X_train, y_train, X_test, y_test\n",
    "    - differentiated: Tuple of X_train_prod, y_train_prod, X_test_prod, y_test_prod\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    # First we need to get the training data\n",
    "    # We will use the first 1913 days as training data and the next\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    # We will also return a second grouping of lists where X_train_prod[i] contains a\n",
    "    # a list of all X_train values for the product i with similar grouping for y_train_prod and test\n",
    "    X_train_prod = []\n",
    "    y_train_prod = []\n",
    "    X_test_prod = []\n",
    "    y_test_prod = []\n",
    "\n",
    "\n",
    "    # get all days that start with d_ and look for the maximum\n",
    "    total_days = max([int(x.split(\"_\")[1]) for x in sales_train_validation_df.columns if \"d_\" in x])\n",
    "    train_days = int(total_days * (1 - test_percentage))\n",
    "    print(\"train days\", train_days)\n",
    "    print(\"test days\", total_days - train_days)\n",
    "    print(\"total days\", total_days)\n",
    "\n",
    "    # Precompute the required data\n",
    "    calendar_df_dict = calendar_df.set_index(\"d\").to_dict(orient=\"index\")\n",
    "    sell_prices_dict = sell_prices_df.groupby([\"item_id\", \"store_id\"])[\"sell_price\"].first().to_dict()\n",
    "\n",
    "    pbar = tqdm(total=len(sales_train_validation_df))\n",
    "    for _, row in sales_train_validation_df.iterrows():\n",
    "        item_id = row[\"item_id\"]\n",
    "        store_id = row[\"store_id\"]\n",
    "\n",
    "        X_train_prod.append([])\n",
    "        y_train_prod.append([])\n",
    "        X_test_prod.append([])\n",
    "        y_test_prod.append([])\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "        valid_size = int((train_days - context_length) * (1 - percentage_omittied))\n",
    "        valid_js = np.random.choice(range(1, train_days - context_length), valid_size, replace=False)\n",
    "\n",
    "        valid_js = list(valid_js) + list(range(train_days, total_days - context_length))\n",
    "\n",
    "        for j in valid_js:\n",
    "            x = []\n",
    "\n",
    "            # Add sales values for the previous context_length days\n",
    "            x.extend(row[f\"d_{j+k}\"] for k in range(context_length))\n",
    "\n",
    "            # Add additional features\n",
    "            current_day = f\"d_{j+context_length}\"\n",
    "            calendar_data = calendar_df_dict[current_day]\n",
    "            x.extend([\n",
    "                calendar_data[\"wday\"],\n",
    "                calendar_data[\"month\"],\n",
    "                store_id,\n",
    "                calendar_data[\"event_name_1\"],\n",
    "                calendar_data[\"event_name_2\"],\n",
    "                sell_prices_dict[(item_id, store_id)],\n",
    "                item_id\n",
    "            ])\n",
    "\n",
    "            if j < train_days:\n",
    "                X_train.append(x)\n",
    "                y_train.append(row[current_day])\n",
    "                X_train_prod[-1].append(x)\n",
    "                y_train_prod[-1].append(row[current_day])\n",
    "\n",
    "            else:\n",
    "                X_test.append(x)\n",
    "                y_test.append(row[current_day])\n",
    "                X_train_prod[-1].append(x)\n",
    "                y_train_prod[-1].append(row[current_day])\n",
    "\n",
    "    undifferentiated = (X_train, y_train, X_test, y_test)\n",
    "    differentiated = (X_train_prod, y_train_prod, X_test_prod, y_test_prod)\n",
    "    return undifferentiated, differentiated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROCESS_FROM_SCRATCH:\n",
    "    undifferentiated, differentiated = proc_train_test(sales_train_validation_df_sub, calendar_df, sell_prices_df_sub, CONTEXT_LENGTH, 0.02, 0.99)\n",
    "    X_train, y_train, X_test, y_test = undifferentiated\n",
    "    X_train_prod, y_train_prod, X_test_prod, y_test_prod = differentiated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_NAMES = [\n",
    "    f\"day_{i}\" for i in range(1, CONTEXT_LENGTH+1)\n",
    "] + [\"wday\", \"month\", \"store_id\", \"event_name_1\", \"event_name_2\", \"sell_price\", \"item_id\"]\n",
    "\n",
    "CAT_COLS = [\"store_id\", \"event_name_1\", \"event_name_2\", \"item_id\", \"wday\", \"month\"]\n",
    "CAT_COLS_IDX = [COL_NAMES.index(col) for col in CAT_COLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train)\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "\n",
    "X_train_df.columns = COL_NAMES\n",
    "X_test_df.columns = COL_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical columns as numbers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Get only label of item_id\n",
    "X_train_df[\"item_id\"] = X_train_df[\"item_id\"].apply(lambda x: x.split(\"_\")[1])\n",
    "X_test_df[\"item_id\"] = X_test_df[\"item_id\"].apply(lambda x: x.split(\"_\")[1])\n",
    "\n",
    "\n",
    "label_encoders = {}\n",
    "for col in CAT_COLS:\n",
    "    le = LabelEncoder()\n",
    "    X_train_df[col] = le.fit_transform(X_train_df[col])\n",
    "    X_test_df[col] = le.transform(X_test_df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "\n",
    "X_train_prod_processed = []\n",
    "X_test_prod_processed = []\n",
    "for i in range(len(X_train_prod)):\n",
    "    X_train_prod_processed.append(pd.DataFrame(X_train_prod[i], columns=COL_NAMES))\n",
    "    X_test_prod_processed.append(pd.DataFrame(X_test_prod[i], columns=COL_NAMES))\n",
    "    X_train_prod_processed[-1][\"item_id\"] = X_train_prod_processed[-1][\"item_id\"].apply(lambda x: x.split(\"_\")[1])\n",
    "    X_test_prod_processed[-1][\"item_id\"] = X_test_prod_processed[-1][\"item_id\"].apply(lambda x: x.split(\"_\")[1])\n",
    "    for col in CAT_COLS:\n",
    "        X_train_prod_processed[-1][col] = label_encoders[col].transform(X_train_prod_processed[-1][col])\n",
    "        X_test_prod_processed[-1][col] = label_encoders[col].transform(X_test_prod_processed[-1][col])\n",
    "\n",
    "X_train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Standard PPCs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def max_ppc(y_true: Float[Array, \"batch y_dim\"], y_samples: Float[Array, \"samples batch y_dim\"], number=0, name=\"\") -> None:\n",
    "    # rpeat y_true to match the shape of y_samples\n",
    "    max_ppc = np.max(y_samples, axis=1)\n",
    "    true_max = np.max(y_true)\n",
    "\n",
    "    return max_ppc.flatten(), true_max.flatten(), \"max_ppc\"\n",
    "\n",
    "def quantile_ppc(y_true: Float[Array, \"batch y_dim\"], y_samples: Float[Array, \"samples batch y_dim\"], quantile=0.5, number=0, name=\"\") -> None:\n",
    "    # rpeat y_true to match the shape of y_samples\n",
    "    q = np.quantile(y_samples, quantile, axis=1)\n",
    "    true_q = np.quantile(y_true, quantile)\n",
    "    return q.flatten(), true_q.flatten(), f\"quantile_ppc_{quantile}\"\n",
    "\n",
    "def zeros(y_true: Float[Array, \"batch y_dim\"], y_samples: Float[Array, \"samples batch y_dim\"], number=0, name=\"\") -> None:\n",
    "    \"Count the number of zeros in the samples\"\n",
    "    zeros = np.sum(y_samples < 0.1, axis=1)\n",
    "    true_zeros = np.sum(y_true < 0.1)\n",
    "\n",
    "    return zeros.flatten(), true_zeros.flatten(), \"zeros\"\n",
    "\n",
    "def percentage_zeros(y_true: Float[Array, \"batch y_dim\"], y_samples: Float[Array, \"samples batch y_dim\"], number=0, name=\"\") -> None:\n",
    "    \"Count the number of zeros in the samples\"\n",
    "    zeros = np.mean(y_samples < 0.1, axis=1)\n",
    "    true_zeros = np.mean(y_true < 0.1)\n",
    "\n",
    "    return zeros.flatten(), true_zeros.flatten(), \"percentage_zeros\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ppcs(y_true: Float[Array, \"batch y_dim\"], y_samples: Float[Array, \"samples batch y_dim\"], ppcs: List[Callable],\n",
    "              number=0, name=\"\") -> None:\n",
    "    # plot the distribution of\n",
    "\n",
    "    for ppc in ppcs:\n",
    "        ppc(y_true, y_samples, number=number, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Complex PPCs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_model_comparisons(data, y_true, figsize=(12, 8), model_names=None):\n",
    "    \"\"\"\n",
    "    Plots model predictions against true values for each day.\n",
    "\n",
    "    :param data: numpy array of shape [models, samples, days] containing model predictions\n",
    "    :param y_true: array of shape [days] containing the true values\n",
    "    :param figsize: tuple indicating the size of the figure\n",
    "    \"\"\"\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    models, samples, days = data.shape\n",
    "\n",
    "    # Create a figure and axis object\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # We will transform the data to a format suitable for seaborn\n",
    "    # Create a DataFrame with model, day, and sample values\n",
    "    plot_data = []\n",
    "    if model_names is None:\n",
    "        model_names = [f\"Model {i}\" for i in range(models)]\n",
    "\n",
    "    for model_idx in range(models):\n",
    "        for day_idx in range(days):\n",
    "            for sample_idx in range(samples):\n",
    "                plot_data.append({\n",
    "                    \"Day\": day_idx,\n",
    "                    \"Value\": data[model_idx, sample_idx, day_idx],\n",
    "                    \"Model\": model_names[model_idx]\n",
    "                })\n",
    "\n",
    "    import pandas as pd\n",
    "    plot_data = pd.DataFrame(plot_data)\n",
    "\n",
    "    # Use seaborn to plot the boxplots\n",
    "    sns.boxplot(x=\"Day\", y=\"Value\", hue=\"Model\", data=plot_data, ax=ax, width=0.6)\n",
    "\n",
    "    # Plot true values\n",
    "    plt.plot(y_true, 'o', color='red', label='True Values')\n",
    "\n",
    "    # Setting labels and title\n",
    "    plt.xticks(ticks=np.arange(days), labels=[f\"Day {i+1}\" for i in range(days)])\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Model Predictions vs. True Values')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_to_pkl(results: dict, dir_name, name):\n",
    "    if not Path(dir_name).exists():\n",
    "        Path(dir_name).mkdir(parents=True)\n",
    "\n",
    "    path = Path(dir_name) / f\"{name}.pkl\"\n",
    "    with open(path, \"wb\") as f:\n",
    "        pkl.dump(results, f)\n",
    "\n",
    "\n",
    "def load_results_from_pkl(dir_name, name):\n",
    "    path = Path(dir_name) / f\"{name}.pkl\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        results = pkl.load(f)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple helper function to train a model and plot ppcs\n",
    "\n",
    "def get_ppcs(y_samples, X_test, y_test, ppcs, number=0, name=\"\") -> None:\n",
    "    \"\"\"\n",
    "    Returns a dictionary with the samples and the true values for each ppc\n",
    "    the dictionary a\n",
    "    \"\"\"\n",
    "    y_samples = np.array(y_samples)\n",
    "    #y_samples = np.maximum(y_samples, 0)\n",
    "    #y_samples = np.round(y_samples, 0)\n",
    "\n",
    "    ppc_results = {}\n",
    "    for ppc in ppcs:\n",
    "        samples, true, name = ppc(y_test, y_samples, number=number, name=name)\n",
    "        ppc_results[name] = {\"samples\": samples, \"true\": true}\n",
    "\n",
    "    return ppc_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_VALUES = 10_000 #len(X_test_df)\n",
    "np.random.seed(0)\n",
    "\n",
    "eval_idx = np.random.choice(len(X_test_df), EVAL_VALUES, replace=False)\n",
    "\n",
    "X_train_np = X_train_df.values\n",
    "X_test_np = X_test_df.values[eval_idx]\n",
    "\n",
    "y_train_np = y_train_df.values + np.random.normal(0, 0.01, y_train_df.shape)\n",
    "y_test_np = y_test_df.values[eval_idx]\n",
    "\n",
    "# change to float to prevent errors\n",
    "y_train_np = y_train_np.astype(np.float32)\n",
    "y_test_np = y_test_np.astype(np.float32)\n",
    "\n",
    "dataset = {\n",
    "    \"X_train\": X_train_np,\n",
    "    \"X_test\": X_test_np,\n",
    "    \"y_train\": y_train_np,\n",
    "    \"y_test\": y_test_np,\n",
    "    \"col_names\": COL_NAMES,\n",
    "    \"cat_cols\": CAT_COLS,\n",
    "}\n",
    "\n",
    "with open(\"dataset.pkl\", \"wb\") as f:\n",
    "    pkl.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = [NGBoostPoisson, Treeffuser]\n",
    "NAMES = [\"NGBoostPoisson\", \"Treeffuser\"]\n",
    "\n",
    "#MODEL_CLASSES = MODEL_CLASSES[-1:]\n",
    "#NAMES = NAMES[-1:]\n",
    "\n",
    "NUM_SAMPLES = 100\n",
    "HYPERS = [\n",
    "    {\"subsample\": 0.20, \"subsample_freq\": 1, \"verbose\": 0, \"num_leaves\":129, \"learning_rate\":0.5,\n",
    "     \"sde_manual_hyperparams\": {\"hyperparam_max\": 10}},\n",
    "    {},\n",
    "    {}\n",
    "]\n",
    "\n",
    "results = []\n",
    "for i in range(len(MODEL_CLASSES)):\n",
    "    model_cls = MODEL_CLASSES[i]\n",
    "    model = BayesOptProbabilisticModel(model_cls, n_iter_bayes_opt=20, frac_validation=0.01)\n",
    "    #model = model_cls(**HYPERS[i])\n",
    "\n",
    "\n",
    "    if model_cls == NGBoostPoisson:\n",
    "        # shuffle the data\n",
    "        np.random.seed(0)\n",
    "        idx = np.random.permutation(len(X_train_np))\n",
    "        X_train_np_ngb = X_train_np[idx]\n",
    "        y_train_np_ngb = y_train_np[idx].astype(np.int32)\n",
    "        model.fit(X_train_np_ngb, y_train_np_ngb)\n",
    "\n",
    "    elif model_cls == NGBoostGaussian:\n",
    "        y_train_np_ngb = y_train_np + np.random.normal(0, 3, y_train_np.shape)\n",
    "        # rescale\n",
    "        #y_train_np_ngb = (y_train_np_ngb - np.mean(y_train_np_ngb)) / np.std(y_train_np_ngb)\n",
    "        model.fit(X_train_np, y_train_np_ngb)\n",
    "\n",
    "    else:\n",
    "        model.fit(X_train_np, y_train_np)\n",
    "\n",
    "    results.append({\n",
    "        \"model\": model,\n",
    "        \"model_name\": NAMES[i]\n",
    "    })\n",
    "\n",
    "    save_results_to_pkl(results, \"m5\", \"results.pkl\")\n",
    "\n",
    "\n",
    "results = load_results_from_pkl(\"m5\", \"results.pkl\")\n",
    "\n",
    "\n",
    "# Save the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, result in enumerate(results):\n",
    "    model = result[\"model\"]\n",
    "    model_name = result[\"model_name\"]\n",
    "    print(f\"Model: {model_name}\")\n",
    "    y_samples = model.sample(X_test_np, NUM_SAMPLES)\n",
    "    results[i][\"y_samples\"] = y_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_no_model = []\n",
    "for result in results:\n",
    "    results_no_model.append({k: v for k, v in result.items() if k != \"model\"})\n",
    "\n",
    "# Don't uncomment or will overwrite the results\n",
    "#save_results_to_pkl(results, \"m5\", \"results_final.pkl\")\n",
    "#save_results_to_pkl(results_no_model, \"m5\", \"results_no_model_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_no_model = load_results_from_pkl(\"m5\", \"results_final.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can actually fit some of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppcs = [max_ppc, zeros, percentage_zeros] + [partial(quantile_ppc, quantile=q) for q in [0.1, 0.5, 0.9, 0.99, 0.999]]\n",
    "\n",
    "for i, model_cls in enumerate(MODEL_CLASSES):\n",
    "    ppc_results = get_ppcs(\n",
    "        y_samples=results_no_model[i][\"y_samples\"],\n",
    "        X_test=X_test_np,\n",
    "        y_test=y_test_np,\n",
    "        ppcs=ppcs,\n",
    "        number=i,\n",
    "        name=model_cls.__name__\n",
    "    )\n",
    "    results[i][\"ppc_results\"] = ppc_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the PPCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titles for plots\n",
    "ppc_tiles = {\n",
    "     \"max_ppc\": \"$\\max$\",\n",
    "      \"zeros\": r\"$\\text{zeros}$\",\n",
    "      \"quantile_ppc_0.99\": \"$q_{0.99}$\",\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_plot_style():\n",
    "    \"\"\"\n",
    "    Sets a common plotting style for all of the figures that will be\n",
    "    used in the final paper.\n",
    "    \"\"\"\n",
    "\n",
    "    # no grid but white with pretty ticks\n",
    "\n",
    "\n",
    "    # use latex font by default\n",
    "    plt.rc(\"text\", usetex=False)\n",
    "    plt.rc(\"font\", family=\"serif\")\n",
    "    sns.set_style(\"white\")\n",
    "\n",
    "    # make it ready for a presentation\n",
    "    sns.set_context(\"talk\")\n",
    "set_plot_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_title(title):\n",
    "    if title in ppc_tiles:\n",
    "        print(\"title\", title)\n",
    "        return ppc_tiles[title]\n",
    "\n",
    "    x = title.replace(\"_\", \" \").capitalize()\n",
    "    x = x.replace(\"ppc\", \"\")\n",
    "    return x\n",
    "\n",
    "ppc_number = len(ppcs)\n",
    "ppc_names = results[0][\"ppc_results\"].keys()\n",
    "\n",
    "for ppc_name in ppc_names:\n",
    "    fig, ax = plt.subplots()\n",
    "    for i, res in enumerate(results):\n",
    "        model_name = res[\"model_name\"]\n",
    "        samples = res[\"ppc_results\"][ppc_name][\"samples\"]\n",
    "        # make int\n",
    "        samples = np.maximum(samples, 0)\n",
    "        samples =  np.round(samples)\n",
    "        true = res[\"ppc_results\"][ppc_name][\"true\"]\n",
    "        n_unique_samples = len(np.unique(samples))\n",
    "        discrete = n_unique_samples < 20\n",
    "\n",
    "        print(\"samples\", samples)\n",
    "\n",
    "        # plot a histogram of the samples but with integers (use nice binning)\n",
    "        if ppc_name == \"max_ppc\":\n",
    "            binwidth = 70\n",
    "        else:\n",
    "            binwidth = None\n",
    "        sns.histplot(samples, ax=ax, label=f\"{model_name}\" + r\" $\\hat{p}$\", discrete=discrete, stat=\"density\", binwidth=binwidth)\n",
    "        if i == 0:\n",
    "            ax.axvline(true, color=\"red\", label=\"Observed Value\")\n",
    "        ax.set_title(proc_title(f\"{ppc_name}\"))\n",
    "        ax.legend()\n",
    "\n",
    "        if n_unique_samples < 2:\n",
    "            min_val = np.min(samples) - 1\n",
    "            max_val = np.max(samples) + 1\n",
    "\n",
    "            ax.set_xlim(min_val, max_val)\n",
    "\n",
    "\n",
    "\n",
    "        # save the figure\n",
    "        fig.savefig(f\"m5/{ppc_name}.png\", dpi=100)\n",
    "        # save as pdf\n",
    "        fig.savefig(f\"m5/{ppc_name}.pdf\")\n",
    "\n",
    "        #max_x = true * 5\n",
    "        #max_samples = np.max(samples)\n",
    "        #if max_samples > max_x:\n",
    "        #    ax.set_xlim(0, max_x)\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, result in enumerate(results):\n",
    "    samples = result[\"y_samples\"][0]\n",
    "    samples = np.round(samples) + (i+1)/4\n",
    "    sns.histplot(samples.flatten(), stat=\"density\", label=result[\"model_name\"])\n",
    "\n",
    "sns.histplot(y_test_np.flatten(), stat=\"density\", color=\"red\", label=\"true\")\n",
    "plt.xlim(0, 10)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "NUM_PRODS_TO_PLOT = 3\n",
    "DAYS_TO_PLOT = 10\n",
    "QUATILE = 0.9\n",
    "NUM_SAMPLES = 100\n",
    "\n",
    "prods_to_plot = np.random.choice(range(len(X_train_prod_processed)), NUM_PRODS_TO_PLOT)\n",
    "\n",
    "means_to_plot = []\n",
    "lower_q_s = []\n",
    "upper_q_s = []\n",
    "\n",
    "prod_dict = {}\n",
    "\n",
    "for res in results:\n",
    "    model = res[\"model\"]\n",
    "\n",
    "    for i in prods_to_plot:\n",
    "        if i not in prod_dict:\n",
    "            prod_dict[i] = {\n",
    "                \"means_to_plot\": [],\n",
    "                \"lower_q_s\": [],\n",
    "                \"upper_q_s\": [],\n",
    "                \"samples\": []\n",
    "            }\n",
    "\n",
    "        X_prod_proc_i = X_train_prod_processed[i][-DAYS_TO_PLOT:]\n",
    "        y_prod_proc_i = y_train_prod[i][-DAYS_TO_PLOT:]\n",
    "\n",
    "        samples = model.sample(X_prod_proc_i.values, NUM_SAMPLES)\n",
    "        samples = samples.astype(int)\n",
    "        samples = np.maximum(samples, 0)\n",
    "\n",
    "        means = np.mean(samples, axis=0)\n",
    "        lower_q = np.quantile(samples, 1-QUATILE, axis=0)\n",
    "        upper_q = np.quantile(samples, QUATILE, axis=0)\n",
    "\n",
    "        prod_dict[i][\"means_to_plot\"].append(means)\n",
    "        prod_dict[i][\"lower_q_s\"].append(lower_q)\n",
    "        prod_dict[i][\"upper_q_s\"].append(upper_q)\n",
    "        prod_dict[i][\"samples\"].append(samples)\n",
    "\n",
    "for i in prod_dict:\n",
    "    means_to_plot = np.array(prod_dict[i][\"means_to_plot\"]).squeeze()\n",
    "    lower_q_s = np.array(prod_dict[i][\"lower_q_s\"]).squeeze()\n",
    "    upper_q_s = np.array(prod_dict[i][\"upper_q_s\"]).squeeze()\n",
    "    samples = np.array(prod_dict[i][\"samples\"]).squeeze()\n",
    "    y_true = np.array(y_train_prod[i][-DAYS_TO_PLOT:])\n",
    "\n",
    "    model_names = [res[\"model\"].__class__.__name__ for res in results]\n",
    "\n",
    "    print(\"mean shape\", means_to_plot.shape)\n",
    "    print(\"lower shape\", lower_q_s.shape)\n",
    "    print(\"upper shape\", upper_q_s.shape)\n",
    "    print(\"y_true shape\", y_true.shape)\n",
    "    print(\"samples shape\", samples.shape)\n",
    "\n",
    "    #plot_predictions(y_true, means_to_plot, upper_q_s, lower_q_s, [res[\"model\"].__class__.__name__ for res in results])\n",
    "    plot_model_comparisons(samples, y_true, model_names=model_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in results:\n",
    "    model = res[\"model\"]\n",
    "    name = res[\"model_name\"]\n",
    "    nll = LogLikelihoodFromSamplesMetric(n_samples=100).compute(model=model, X_test=X_test_np, y_test=y_test_np, samples=res[\"y_samples\"])\n",
    "    crps  = CRPS().compute(model=model, X_test=X_test_np, y_test=y_test_np, samples=res[\"y_samples\"])\n",
    "    print(f\"Model {name} has a NLL of {nll}\")\n",
    "    print(f\"Model {name} has a CRPS of {crps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot calibration plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_plot(y_samples: Float[np.ndarray, \"n_samples batch y_dim\"], y_test: Float[np.ndarray, \"batch y_dim\"]) -> None:\n",
    "    \"\"\"\n",
    "    We will plot the calibration plot for the model. Essentially, we will plot the\n",
    "    \"\"\"\n",
    "    assert y_test.shape[1] == 1, \"Only works for univariate outputs\"\n",
    "    n_samples = y_samples.shape[0]\n",
    "    y_samples = np.maximum(y_samples, 0.0)\n",
    "    y_samples = np.round(y_samples).astype(int)\n",
    "    y_test = y_test.astype(int)\n",
    "\n",
    "    # Filter out the zeros\n",
    "    #non_zero_idx = y_test > 0\n",
    "    #y_test = y_test[non_zero_idx]\n",
    "    #y_samples = y_samples[:, non_zero_idx]\n",
    "\n",
    "    y_test_expanded = y_test[np.newaxis, :].repeat(n_samples, axis=0)\n",
    "    prob_of_event = np.mean(y_samples <= y_test_expanded, axis=0)\n",
    "    prob_of_event_sorted = np.sort(prob_of_event.flatten())\n",
    "    return np.linspace(0, 1, len(prob_of_event)), prob_of_event_sorted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ex = None\n",
    "for res in results:\n",
    "    samples = res[\"y_samples\"]\n",
    "    model = res[\"model\"]\n",
    "    x,y = calibration_plot(samples, y_test_np)\n",
    "    plt.plot(x, y, label=res[\"model_name\"])\n",
    "    y_ex = y\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"black\")\n",
    "\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"True Probability\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plot the distribution of y\n",
    "\n",
    "sns.histplot(y_ex, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantile prediction plot for the model\n",
    "def make_quantile_plot(results):\n",
    "    quantiles = np.linspace(0.9, 0.999, 10)\n",
    "\n",
    "    means = []\n",
    "    stds = []\n",
    "\n",
    "    for res in results:\n",
    "        samples = res[\"y_samples\"] # shape [n_samples, batch, y_dim]\n",
    "        samples = np.maximum(samples, 0)\n",
    "        samples = np.round(samples)\n",
    "\n",
    "        m, s = [], []\n",
    "\n",
    "        for q in quantiles:\n",
    "            quantile_samples = np.quantile(samples, q, axis=1)\n",
    "            mean = np.mean(quantile_samples, axis=0)\n",
    "            std = np.std(quantile_samples, axis=0)\n",
    "            m.append(mean)\n",
    "            s.append(std)\n",
    "\n",
    "        m = np.array(m).squeeze()\n",
    "        s = np.array(s).squeeze()\n",
    "        plt.plot(quantiles, m, label=res[\"model_name\"])\n",
    "        plt.fill_between(quantiles, m - s, m + s, alpha=0.3)\n",
    "\n",
    "        means.append(m)\n",
    "        stds.append(s)\n",
    "\n",
    "\n",
    "    true_quantiles =  []\n",
    "    for q in quantiles:\n",
    "        true_quantiles.append(np.quantile(y_test_np, q))\n",
    "\n",
    "    plt.plot(quantiles, true_quantiles, label=\"True\")\n",
    "\n",
    "    # set log scale on y axis\n",
    "\n",
    "\n",
    "    # set log scale on x axis\n",
    "    plt.xscale(\"log\")\n",
    "    plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_quantile_plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
